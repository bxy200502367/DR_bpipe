# DR_bpipe2.0开发档案
开发者：徐园  
编撰日期：2022年1月28日

>## **用法**
```shell
usage：sh 脚本 存放barcode文件的文件地址 NC PC
（结果存放于运行目录的result文件夹内）
```

三个参数 ：   
第一个参数：存放barcode文件的文件地址（如/home/chensy/xu_test/20210802_PCRM53_test/PCRM53_called_guppy）  
第二个参数：NC样本所对应的barcode号（如barcode23）  
第三个参数：PC样本所对应的barcode号（如barcode24）  

>## **模块**
DR_bpipe2.0版本主要是6大模块组成  
>>**1. AMR模块（分析耐药基因有无）**  
**2. SNP模块（分析点突变）**  
**3. SGA_001模块（分析小片段Indel）**  
**4. SGA_002模块（分析大片段插入）**  
**5. SGA_003模块（分析基因型别）**   
**5. MLST模块（分析保守基因的MLST型）**  

>>### ***AMR模块***
AMR模块是**分析耐药基因有无的模块**  
last软件比对 过滤identity<85% alignment_length<400的测序read  
并统计每一个耐药基因的深度  

**结果**:
1. AMR_result.xlsx 深度统计表（包括Total和Total-phage两列)  
2. AMR_result_detail.xlsx 带有辅助判断的深度统计表（Ave_Length；Ave_Score;Ave_Identity）
3. AMR_TF_result.xlsx  
    首先通过样本中phage是否大于0.8倍PC样本中的phage值，**判断样本是否有问题**  
    其次通过下面的模型**判断基因的真假阳性**
    >AMR_depth >= 100 & AMR_depth > 0.4*PC & AMR_depth >= 2*NC) | AMR_depth > 600

    结果用T/F判断

**说明**：
1. AMR模块中**phage**是一个常量，在reference中标签名最好不变，不然会引起系统性问题
2. 各样本AMR_analysis文件夹下会存在**abstract_fastq**和**abstract_fasta**文件夹，里面存放从原始测序文件中提取的比对上的reads
3. xlsx结果用python的openpyxl模块进行了优化，详细可以参照`Module/sub/merge_result.py`中`beautiful_excel()`方法
4. 目前样本名即输入文件夹下的文件名，未改成BC

**改进**
1. 辅助判断参数没有加上覆盖度作为一个评价指标
2. 可以根据需要给予AMR模块的基因不同的标签，后续可以根据标签进行后续功能的开发  
    比如`AMR100_SR`的**SR**标签意味着这是一个短扩增子产物，可以通过不同的过滤参数个性化分析；
    比如`AMR101_VF`的**VF**标签意味着这是一个需要加上后续验证的基因
    基于不同的标签可以进行后续个性化的分析


>>### ***SNP模块***
SNP模块是**分析某些耐药基因点突变的模块**  
last软件比对 过滤identity<85% alignment_length<400的测序read  
samtools排序并且生成mpileup格式
并统计每一个基因每一个位置的碱基情况  
并将碱基按照三联体密码子的规则转化成氨基酸形式

**结果**:
1. SNP_result.xlsx 点突变统计表（无深度限制)  

**说明**：
1. SNP_result.xlsx结果中只要有点突变的可能就检出，如果是该基因不存在样本中，则以(0)表示,意味着该基因深度为0；如果是野生型则以(depth)表示且没有点突变形式，则意味着该基因为野生型且深度为depth
2. 终止密码子在之前的版本中以stop_codon表示，这里以下划线_表示，主要考虑后续的分析
3. SNP模块只考虑点突变的信息，未考虑Indel的影响，对于gyrA类很少涉及Indel类型的基因有很好的分析结果
4.可以通过特定的SNP结果进行物种鉴定（开发Species子模块）

**改进**
1. 基因的每一个位置既有碱基的情况（A、T、C、G、insert、deletion甚至简并碱基），还有每一个碱基的质量信息（ascill码形式存在），质控中Q8是指read平均质量在8以上的过滤，是**整体平均值**，完全可以对单碱基卡一个阈值
2. 可以提取特定位置的点突变信息，如果能够找出规律就再好不过了

>>### ***SGA_001模块***
SGA_001模块是**分析短片段插入缺失的模块**  
last软件比对 过滤identity<85% alignment_length<400的测序read  
samtools排序并且生成mpileup格式
并统计每一个基因每一个位置的碱基情况  
VarScan.v2.3.9.jar进行Indel的识别 

**结果**:
1. SGA_001_result.xlsx 突变结果（depth<10标记为LD(低深度，Low Depth)；如果存在插入缺失或者提前终止密码子标记为SM（强突变，strong Mutation）；如果存在除提前终止密码子外的点突变标记为WM（弱突变，Weak Mutation）；没有点突变也没有插入缺失标记为W（野生型，Wild））

**说明**：
1. SGA_001其实是分析PA-4基因的模块

**改进**
1. SGA_001其实是分析PA-4基因的模块，目前没有可拓展功能，只能分析一个基因，但是可以reference替换成其它类似的基因
2. PA-4基因分析过程中发现扩增子起始部分会存在固定的点突变（引物结合区？）后续可以删除这几个位置的突变信息

>>### ***SGA_002模块***
SGA_002模块是**分析长片段插入的模块**  
last软件比对 不经过QC过程  
提取比对的其实和终止位置（存在突变会存在两段结果，起始和终止点所占的百分比构建一个模型，阈值为120%）

**结果**:
1. SGA_002_result.xlsx 长片段插入结果（depth<10标记为LD(低深度，Low Depth)；如果存在长片段插入标记为M（突变，Mutation）并输出预测断点；如果不存在则标记为W（野生型，Wild））

**说明**：
1. SGA_002其实是分析adeN基因的模块，目前可以拓展，reference中可以放入多个基因，会自动判断比对起始和终止位置，然后进行后续分析，所以reference一定要囊括比对的起始和终止点

**改进**
1. 对大片段插入的检出率很好，但是如果插入位置太靠前和太靠后（50bp以内）如ompF基因就会导致结果不可信，是否可以通过重新设计引物解决
2. 预测断点的模型可以再优化（目前采用中间百分率突然变大的位置作为断点预测）

>>### ***SGA_003模块***
SGA_003模块是**分析遗传背景的模块**  
类似于组装的过程，通过深度+点突变+Indel进行校正
生成一个fit_fasta,然后和二级数据库比对，寻找best_match结果

**结果**:
1. SGA_003_result.xlsx 遗传背景（会有best_matches(E16_Efs_1_85) identity(97.358) mismatches(14) gap(0) depth(2)这5个结果不详细展开）

**说明**：
1. SGA_003其实是分析KPC-2基因的模块衍生的，目前可以拓展，reference中可以放入多个基因

>>### ***MLST模块***
MLST模块是**分析遗传背景的模块**  
*和SGA_003模块不同的是SGA_003模块考虑了Indel的情况，MLST不考虑Indel情况，只考虑点突变情况*适合MLST一类管家基因的研究

**结果**:
1. MLST_result.xlsx 遗传背景（会有best_matches(E16_Efs_1_85) identity(97.358) mismatches(14) gap(0) depth(2)这5个结果不详细展开）

>## **数据库**
**目前的版本各个模块独立分析**  
保证了相互之前不会影响，也会导致结果之间会有细微区别  
每个模块都需要一个reference

>>### 一级数据库
即reference，Module/Reference里面存放各个模块需要的reference  

*注意*：
1. AMR模块必须要有phage
2. SGA_001模块只能有一条基因
3. SGA_002模块reference一定要囊括比对的起始和终止点
4. fasta格式>标签后的基因名不能有空格、名字不能重名（最好不要，会导致不可预料的问题）

>>### 二级数据库
只有SGA_003和MLST模块需要二级数据库
二级数据库存放的是所有的亚型结果
Module/database里面存放这两个模块需要的database

>## **质控**
**目前采用Nanofilt质控**  
Nanofilt对Nanopore测序质量有比较好的支持

>>### Q值过滤
Q7作为阈值，Q值得概率和公式百度

>>### 长度过滤
测序长度在400~1500之间
低长度片段主要是考虑到引物二聚体的情况
高长度片段主要是考虑嵌合体的情况
当然可以通过测序仪器的barccode设置优化或者独立的检测软件

>## **架构**
**本人采用的是bpipe架构**
架构看下图Module/DR.bpipe
```
about title: "耐药分析流程"
Bpipe.run {
	 "%.fastq" * [QC + [AMR, SNP, SGA_001, SGA_003, MLST],SGA_002]
}
```
**优点：**

    1. 流程易于后期维护，寻找bug
	重新架构以后，所有模块相对独立，相互之间不影响

	2. 流程方便后续开发
	代码可读性增强
	
	3. 高并行
	每个样本每个模块都给予并行处理

	4. 冗余文件减少，占用空间少
	运行结束，中间冗余文件删除（可恢复中间文件可用于后续开发）

bpipe架构优点就是高并发并且对cpu的使用率少  
特别是在服务器有大量其它任务的挤占，依然保持比较好的性能  
当然可以选择其它的架构，如SnakeMake或者Nextflow  
**个人推荐Nextflow**

>## **持续优化建议**
**个人意见**
1. barcode优化：barcode会存在分选错误的情况
2. 比对方法优化：  
***比对软件***：  本人采用Last比对软件，主要是对长片段比对有比较好的敏感度和阳性率，当然可以采用其它的工具（多个比对工具测试过）  
***比对打分矩阵的修改***：  本人的打分矩阵错配-1，匹配+1，gap-1，gap延伸-1（测试过但未优化last有个自带的last—train工具可以优化）
3. 现在的结果是用xlsx储存，后续可以加个数据库
    比较好的是轻量级的sqlite，因为本人merge_result的功能是用python写的，python对sqlite有比较好的接口，同样的对前端也有比较好的扩展接口
